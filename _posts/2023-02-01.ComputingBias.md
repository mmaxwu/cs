---
toc: true
layout: post
description: 
title: Computing Bias
categories: [Week 22, jupyter]
---

## Discussions

1. 25-34 is the age group that uses facebook and 10-19 is the age group that uses TikTok. There is no purposeful exclusion in these platforms; they just target certain demographics. This is harmful because different age groups receiving different types of information creates division between the different age groups. This should be corrected due to the reasons I just stated above. Despite creating division, it is good business strategy because a platform cannot appeal to everyone, because different age groups have different interests and different humor. 

2. Virtual assistants have female voices because companies spent decades acquiring many more recordings of women's voices than of men's, so they just kept on building on that data. This isn't a good thing because younger people growing up might assume that women 

3. The Google search engine, powered by a complex network of big data and machine learning algorithms, heavily impacts my decision making by providing me with a list of website links relevant to my search query. This algorithm can significantly alter the information I consume and learn online, as well as affect my internet entertainment experience. For instance, Netflix uses a similar approach with its recommendation engine to suggest shows to users based on their viewing history or current trends.



## As Pairs
1. Does the owner of the computer think this was intentional?
   I do not believe that the owner of the computer thought that this was intentional.
2. If yes or no, justify you conclusion.
    The overall video had a pretty humorous tone, and it didn’t seem like the owner was really agitated in any way. However, had he been more concerned with the quality of the product, he likely would’ve brought it up in a more official way, by filling out a ticket or sending an email to customer support directly.
3. How do you think this happened?
    I think that this likely happened because of a lack of training data for the computer to work with, as if the computer is only trained to recognize people or lighter skin tones, it might not necessarily work as well for people of other skin tones.
4. Is this harmful? Was it intended to be harmful or exclude?
    Such mistakes are certainly harmful, although their might not be intended to be harmful or to exclude. These mistakes allow for an entire demographic to miss out on a particular technology or trend.
5. Should it be corrected?
    Yes, I believe that this issue should be corrected in order to incorporate and embrace a much larger group of consumers
6. What would you or should you do to produce a better outcome?
    I believe that if the company could use more training data (i.e. getting more people from different races and skin tones to test out the computer), performance would gradually increase to include other people as well.
